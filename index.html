---
layout: default
title: Home
---



<div class="container">

    
  <h2 class="page-title">News </h2>  
  <div>
    <ul>
      <li> <p class="content-home"> [Dec 2018] <a href="https://doi.org/10.1016/j.imavis.2018.11.001"> Our colorcheck paper is accepted to IMAVIS!!!</a> </p> </li>
    </ul>
  </div>

  <h2 class="page-title">Publications </h2>  
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10"> 
    


    <!-- item 0  -->

    <tr>         
      <td width="20%" valign="top">
        <!-- image -->
        <div class="col-sm-2 project-thumbnail-home"></div>
        <img src="https://github.com/pedrodiamel/ferattention/raw/master/rec/emotion.gif" class="img-responsive-home" alt="ContextLocNet">
        </div>

        <!-- description -->
        <td width="80%" valign="top">
          <div class="project-title-home">
          <strong>FERAtt: Facial Expression Recognition with Attention Net</strong>
          </div>          
          <div class="project-description-home">
            Pedro D. Marrero Fernández, Fidel A. Guerrero Peña, Tsang Ing Ren, Alexandre Cunha ; <em> - </em> 2019
          </div>
          <div class="project-links-home" id="attfer_bib" >            
            [<a href=" ">paper</a>] &nbsp;
            [<a href="https://arxiv.org/abs/1902.03284">arxiv</a>] &nbsp;
            [<a href="https://github.com/pedrodiamel/ferattention">code</a>] &nbsp;
            [<a href="javascript:toggleblock('attfer_abs')">abstract</a>] &nbsp;
            [<a href="javascript:togglebib('attfer_bib')" shape="rect" class="togglebib">bibtex</a>] &nbsp;

            <div class="bibtex-home"  >
              <p align="justify" > <i id="attfer_abs" style="display: none;"> Pytorch implementation for FERAtt neural net. Facial Expression Recognition with Attention Net (FERAtt), is based on the dual-branch architecture and consists of four major modules: (i) an attention module $G_{att}$ to extract the attention feature map, (ii) a feature extraction module $G_{ft}$ to obtain essential features from the input image $I$, (iii) a reconstruction module $G_{rec}$ to estimate a good attention image $I_{att}$, and (iv) a representation module $G_{rep}$ that is responsible for the representation and classification of the facial expression image. </i></p>
              <pre style="display: none;">
@article{fernandez2019feratt,
  title={FERAtt: Facial Expression Recognition with Attention Net},
  author={Fernandez, Pedro D Marrero and Pe{\~n}a, Fidel A Guerrero 
          and Ren, Tsang Ing and Cunha, Alexandre},
  journal={arXiv preprint arXiv:1902.03284},
  year={2019}
}
              </pre> 
            </div>
          </div>
        </td> 
      </tr>
      </td>
    </tr>



    <!-- item 1 -->
    <tr>         
      <td width="20%" valign="top">
        <!-- image -->
        <div class="col-sm-2 project-thumbnail-home"></div>
        <img src="https://github.com/pedrodiamel/colorchecker-detection/raw/master/rec/mcc.gif" class="img-responsive-home" alt="ContextLocNet">
        </div>

        <!-- description -->
        <td width="80%" valign="top">
          <div class="project-title-home">
          <strong>Fast and Robust Multiple ColorChecker Detection using Deep Convolutional Neural Networks</strong>
          </div>          
          <div class="project-description-home">
            Pedro D. Marrero Fernández, Fidel A. Guerrero Peña, Tsang Ing Ren, Jorge J.G. Leandro; <em>Image and Vision Computing</em> 2019
          </div>
          <div class="project-links-home" id="colorchecker_detection" >            
            [<a href="https://doi.org/10.1016/j.imavis.2018.11.001">paper</a>] &nbsp;
            [<a href="https://arxiv.org/abs/1810.08639" >arxiv</a>] &nbsp;
            [<a href="https://github.com/pedrodiamel/colorchecker-detection">code</a>] &nbsp;
            [<a href="javascript:toggleblock('colorchecker_detection_abs')">abstract</a>] &nbsp;
            [<a href="javascript:togglebib('colorchecker_detection')" shape="rect" class="togglebib">bibtex</a>] &nbsp;

            <div class="bibtex-home"  >
              <p align="justify" > <i id="colorchecker_detection_abs" style="display: none;"> ColorCheckers are reference standards that professional photographers and filmmakers use to ensure predictable results under every lighting condition. The objective of this work is to propose a new fast and robust method for automatic ColorChecker detection. The process is divided into two steps: (1) ColorCheckers localization and (2) ColorChecker patches recognition. For the ColorChecker localization, we trained a detection convolutional neural network using synthetic images. The synthetic images are created with the 3D models of the ColorChecker and different background images. The output of the neural networks are the bounding box of each possible ColorChecker candidates in the input image. Each bounding box defines a cropped image which is evaluated by a recognition system, and each image is canonized with regards to color and dimensions. Subsequently, all possible color patches are extracted and grouped with respect to the center's distance. Each group is evaluated as a candidate for a ColorChecker part, and its position in the scene is estimated. Finally, a cost function is applied to evaluate the accuracy of the estimation. The method is tested using real and synthetic images. The proposed method is fast, robust to overlaps and invariant to affine projections. The algorithm also performs well in case of multiple ColorCheckers detection. </i></p>
              <pre style="display: none;">
@article{MARREROFERNANDEZ2018,
    title = "Fast and Robust Multiple ColorChecker Detection 
             using Deep Convolutional Neural Networks",
    journal = "Image and Vision Computing",
    year = "2018",
    issn = "0262-8856",
    author = "Pedro D. Marrero Fernández and Fidel A. Guerrero Peña 
              and Tsang Ing Ren and Jorge J.G. Leandro",
  }
              </pre> 
            </div>
          </div>
        </td> 
      </tr>
      </td>
    </tr>
      
    <!-- item 2 -->
   

    <!-- item 3 -->



  </table>

  <h2 class="page-title">Abaut Me </h2> 
  <p>My name is Pedro Diamel Marrero Fernandez, I'm Computer Science PhD student at the <a href="http://www.cin.ufpe.br">Informatics Center (CIn)</a>, <a href="http://www.ufpe.br">Federal University of Pernambuco</a>. I'm passionate about deep learning with a strong focus on Computer Vision and Image Processing. Currently, I'm an artificial intelligence researcher at Motorola LLC - CIn partnership Lab. </p>


  

</div>


<!-- <div class="container"> -->

  <!-- {% comment %} 
  <img src="{{ site.baseurl }}{{ site.hero.image }}" />
  <p>{{ site.hero.caption }}</p> 
  {% endcomment %} -->
  

  <!-- <div class="main">

      <h1>Pedro D. Marrero Fernandez</h1>
      <h2>Image processing | Computer Vision | Machine Learning</h2>
      <div class="social-icons">
        <a class="svg" href="https://github.com/pedrodiamel" >
          <object type="image/svg+xml" data="public/img/github.svg" id="github"></object>
        </a>
        <a class="svg" href="https://pl.linkedin.com/in/pedro-diamel/en">
          <object type="image/svg+xml" data="public/img/linkedin.svg" id="linkedin"></object>
        </a>
        <a class="svg" href="https://twitter.com/Pedrodiamel">
          <object type="image/svg+xml" data="public/img/twitter.svg" id="twitter"></object>
        </a>
        <a class="svg" href="mailto:pedrodiamel@gmail.com">
          <object type="image/svg+xml" data="public/img/envelope.svg" id="mail"></object>
        </a>
      </div>

      <div class="under-construction">
        <h2 class="blog-msg"><a href="/blog/index.html">This website is currently under construction, but I've got a fully functional blog (click here)!</a></h2>  
      </div>

    </div> -->

<!-- </div> -->
